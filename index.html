<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Air Letter Tracing</title>
  <style>
    body, html {
      margin: 0;
      overflow: hidden;
      width: 100%;
      height: 100%;
    }
    #videoElement, #canvasElement {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #videoElement {
      transform: scaleX(-1); /* Mirror the video for natural interaction */
    }
  </style>
</head>
<body>
  <video id="videoElement" autoplay playsinline></video>
  <canvas id="canvasElement"></canvas>

  <!-- Load TensorFlow.js and the Hand Pose Detection model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection@2.0.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/hands.js"></script>

  <script>
    (async () => {
      // References to video and canvas elements
      const video = document.getElementById('videoElement');
      const canvas = document.getElementById('canvasElement');
      const ctx = canvas.getContext('2d');

      let detector;
      let currentDotIndex = 0;

      // Define the letter as a series of relative coordinates
      const letterDots = [
        { x: 0.5, y: 0.2 },
        { x: 0.3, y: 0.8 },
        { x: 0.7, y: 0.8 },
        { x: 0.4, y: 0.5 },
        { x: 0.6, y: 0.5 },
      ];

      // Function to set up the camera
      async function setupCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user' },
            audio: false,
          });
          video.srcObject = stream;
          await new Promise((resolve) => {
            video.onloadedmetadata = () => {
              resolve();
            };
          });
        } catch (error) {
          alert('Error accessing camera: ' + error.message);
          console.error('Camera Error:', error);
        }
      }

      // Function to load the hand pose model
      async function loadHandPoseModel() {
        try {
          const model = handPoseDetection.SupportedModels.MediaPipeHands;
          const detectorConfig = {
            runtime: 'tfjs',
            modelType: 'lite', // Use 'lite' model for better performance on mobile
            maxHands: 1,
          };
          detector = await handPoseDetection.createDetector(model, detectorConfig);
        } catch (error) {
          alert('Error loading hand pose model: ' + error.message);
          console.error('Model Loading Error:', error);
        }
      }

      // Function to resize canvas to match video dimensions
      function resizeCanvas() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      }

      // Function to draw the letter dots
      function drawDots() {
        letterDots.forEach((dot, index) => {
          const dotX = dot.x * canvas.width;
          const dotY = dot.y * canvas.height;

          if (index < currentDotIndex) {
            ctx.fillStyle = 'white';
          } else if (index === currentDotIndex) {
            ctx.fillStyle = 'green';
          } else {
            ctx.fillStyle = 'rgba(128, 128, 128, 0.5)';
          }
          ctx.beginPath();
          ctx.arc(dotX, dotY, 20, 0, Math.PI * 2);
          ctx.fill();
        });
      }

      // Function to draw hand landmarks
      function drawHand(hand) {
        if (hand.keypoints && hand.keypoints.length > 0) {
          ctx.fillStyle = 'red';
          hand.keypoints.forEach((point) => {
            const x = canvas.width - (point.x * canvas.width / video.videoWidth);
            const y = point.y * canvas.height / video.videoHeight;
            ctx.beginPath();
            ctx.arc(x, y, 5, 0, 2 * Math.PI);
            ctx.fill();
          });
        }
      }

      // Main function to process video frames
      async function mainLoop() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        drawDots();

        try {
          const hands = await detector.estimateHands(video);

          if (hands.length > 0) {
            const hand = hands[0];
            drawHand(hand);

            const indexFingerTip = hand.keypoints.find(p => p.name === 'index_finger_tip');
            if (indexFingerTip) {
              const fingerX = canvas.width - (indexFingerTip.x * canvas.width / video.videoWidth);
              const fingerY = indexFingerTip.y * canvas.height / video.videoHeight;

              // Draw the fingertip marker
              ctx.fillStyle = 'blue';
              ctx.beginPath();
              ctx.arc(fingerX, fingerY, 10, 0, 2 * Math.PI);
              ctx.fill();

              // Check for collision with current dot
              const targetDot = letterDots[currentDotIndex];
              const targetX = targetDot.x * canvas.width;
              const targetY = targetDot.y * canvas.height;

              const distance = Math.hypot(fingerX - targetX, fingerY - targetY);
              if (distance < 40) {
                currentDotIndex++;
                if (currentDotIndex >= letterDots.length) {
                  alert('Well done! You have traced the letter.');
                  currentDotIndex = 0; // Reset
                }
              }
            }
          }
        } catch (error) {
          console.error('Hand Detection Error:', error);
        }

        requestAnimationFrame(mainLoop);
      }

      // Initialize the application
      async function init() {
        await setupCamera();
        await loadHandPoseModel();

        video.play();

        // Adjust canvas size when video metadata is loaded
        video.addEventListener('loadeddata', () => {
          resizeCanvas();
        });

        // Adjust canvas size on window resize
        window.addEventListener('resize', resizeCanvas);

        mainLoop();
      }

      init();
    })();
  </script>
</body>
</html>