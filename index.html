<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Air Letter Tracing</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #videoElement, #canvasElement {
      position: absolute;
      top: 0;
      left: 0;
    }
    #videoElement {
      transform: scaleX(-1); /* Mirror the video feed for a more intuitive experience */
    }
  </style>
</head>
<body>
  <video id="videoElement" width="640" height="480" autoplay playsinline></video>
  <canvas id="canvasElement" width="640" height="480"></canvas>

  <!-- Load TensorFlow.js and the HandPose model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

  <script>
    // Get references to the video and canvas elements
    const video = document.getElementById('videoElement');
    const canvas = document.getElementById('canvasElement');
    const ctx = canvas.getContext('2d');

    let handposeModel;
    let currentDotIndex = 0;

    // Define the letter 'A' as a series of dots
    const letterDots = [
      { x: 320, y: 100 },
      { x: 220, y: 380 },
      { x: 420, y: 380 },
      { x: 270, y: 240 },
      { x: 370, y: 240 },
    ];

    // Access the user's webcam
    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 480 },
        audio: false,
      });
      video.srcObject = stream;
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve();
        };
      });
    }

    // Load the HandPose model
    async function loadHandposeModel() {
      handposeModel = await handpose.load();
    }

    // Draw the dots on the canvas
    function drawDots() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      letterDots.forEach((dot, index) => {
        if (index < currentDotIndex) {
          ctx.fillStyle = 'white';
        } else if (index === currentDotIndex) {
          ctx.fillStyle = 'green';
        } else {
          ctx.fillStyle = 'rgba(128, 128, 128, 0.5)';
        }
        ctx.beginPath();
        ctx.arc(dot.x, dot.y, 15, 0, Math.PI * 2);
        ctx.fill();
      });
    }

    // Main loop to detect hands and update the UI
    async function mainLoop() {
      const predictions = await handposeModel.estimateHands(video, true);

      drawDots();

      if (predictions.length > 0) {
        const landmarks = predictions[0].landmarks;
        const indexFingerTip = landmarks[8]; // Index finger tip

        // Convert 3D coordinates to 2D canvas coordinates
        const fingerX = indexFingerTip[0];
        const fingerY = indexFingerTip[1];

        // Draw the fingertip position
        ctx.fillStyle = 'red';
        ctx.beginPath();
        ctx.arc(fingerX, fingerY, 10, 0, Math.PI * 2);
        ctx.fill();

        // Check if the fingertip is close to the current dot
        const targetDot = letterDots[currentDotIndex];
        const distance = Math.hypot(fingerX - targetDot.x, fingerY - targetDot.y);

        if (distance < 30) {
          currentDotIndex++;
          if (currentDotIndex >= letterDots.length) {
            alert('Well done! You have traced the letter.');
            currentDotIndex = 0; // Reset for the next round
          }
        }
      }

      requestAnimationFrame(mainLoop);
    }

    // Initialize the application
    async function init() {
      await setupCamera();
      await loadHandposeModel();
      video.play();
      mainLoop();
    }

    init();
  </script>
</body>
</html>